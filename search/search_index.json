{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Iris is a system to coordinate complex network measurements from multiple vantage points. Think of it as a project similar to CAIDA Ark or RIPE Atlas, with the following features:</p> <ul> <li>Fully open-source code.</li> <li>Handle multi-round measurements, such as diamond-miner IP tracing measurements.</li> <li>Handle both centralized computation on a powerful server, and distributed probing on smaller agents.</li> <li>Can tolerate the temporary loss of agents, database or control-plane components.</li> </ul> <p>We offer a public instance of Iris, as well as public measurement data, on iris.dioptra.io.</p>"},{"location":"api/","title":"HTTP API","text":"<p>Iris is meant to be controlled through an HTTP API. The API is documented with Swagger on the <code>/docs</code> endpoint. A documentation of the API is publicly available at https://api.iris.dioptra.io/docs/.</p> <p>On this page we document specific tips for using the API.</p>"},{"location":"api/#registering","title":"Registering","text":""},{"location":"api/#on-irisdioptraio","title":"On iris.dioptra.io","text":"<p>To register on Iris public instance, you must go through iris.dioptra.io. Upon registration, you will be invited to sign a license and send it to our team for approval. Once your account is approved you will be able to access public Iris data.</p>"},{"location":"api/#on-a-private-instance","title":"On a private instance","text":"<p>To register on a private instance, you can use the <code>/auth/register</code> endpoint: <pre><code>curl -X POST \\\n    -H 'Content-Type: application/json' \\\n    -d '{\"firstname\": \"First\", \"lastname\": \"Last\", \"email\": \"a@b.c\", \"password\": \"abc\"}' \\\n    https://api.dev.iris.dioptra.io/auth/register\n</code></pre></p> <pre><code>{\n  \"id\": \"23ec99b5-f259-4732-b121-d012b686e37a\",\n  \"email\": \"a@b.c\",\n  \"is_active\": true,\n  \"is_superuser\": false,\n  \"is_verified\": false,\n  \"firstname\": \"First\",\n  \"lastname\": \"Last\",\n  \"probing_enabled\": false,\n  \"probing_limit\": 1,\n  \"allow_tag_reserved\": false,\n  \"allow_tag_public\": false,\n  \"creation_time\": \"2022-08-17T14:24:22.495581\"\n}\n</code></pre> <p>An administrator can then set <code>is_verified</code> and <code>probing_enabled</code> to true by issuing a PATCH query against the <code>/users/:id</code> endpoint.</p>"},{"location":"api/#iris-client","title":"iris-client","text":"<p>To make it easier to use the Iris API from Python code, you can use the iris-client library. It is implemented on top of httpx and has sync and async interfaces.</p> <pre><code>pip install dioptra-iris-client\n</code></pre> <p>To avoid specifying the credentials in the code, you can use environment variables, or a configuration file:</p> ~/.config/iris/credentials.json<pre><code>{\n    \"base_url\": \"https://api.iris.dioptra.io\",\n    \"username\": \"admin@example.org\",\n    \"password\": \"admin\"\n}\n</code></pre> <pre><code>from iris_client import IrisClient\n\nwith IrisClient() as iris:\n    iris.all(\"/measurements/\", params={\"tag\": \"collection:public\", \"only_mine\": False})\n    iris.post(\"/measurements/\", json={\"tool\": \"diamond-miner\", \"agents\": \"...\"})\n</code></pre> <p>For more information, refer to the documentation of the library.</p>"},{"location":"api/#pych-client","title":"pych-client","text":"<p>To access Iris data hosted on ClickHouse, you can use the pych-client library in combination with iris-client.</p> <pre><code>pip install pych-client\n</code></pre> <pre><code>from iris_client import IrisClient\nfrom pych_client import ClickHouseClient\n\nwith IrisClient() as iris:\n    services = iris.get(\"/users/me/services\").json()\n    with ClickHouseClient(**services[\"clickhouse\"]) as clickhouse:\n        print(clickhouse.json(\"SHOW TABLES\"))\n</code></pre>"},{"location":"concepts/","title":"Concepts","text":""},{"location":"concepts/#agent","title":"Agent","text":"<p>An agent performs measurements. It receives a list of probes to send and uses caracal to send the probes and capture the replies. It is implemented as Python application that loops on a Redis queue and uploads the results to an S3 bucket.</p> <p>The resources required to run an agent are minimal and depends mostly on the desired probing rate. A minimum of 1 CPU and 512 MB of memory are required. To achieve a rate of 100k packets per second, we recommend at-least 2 CPU.</p> <p>If you're running an agent in the cloud, avoid burstable instances since the agent will exhaust the CPU credits very quickly and will become very slow.</p>"},{"location":"concepts/#measurement","title":"Measurement","text":"<p>A measurement is defined by a tool and a list of measurement agents.</p>"},{"location":"concepts/#measurement-agent","title":"Measurement agent","text":"<p>A measurement agent is defined by an agent, a target list and tool parameters specific to the agent.</p>"},{"location":"concepts/#target-list","title":"Target list","text":"<p>A target list is a comma-delimited list of networks to probe. Each line of the file must be like <pre><code>target,protocol,min_ttl,max_ttl,n_initial_flows\n</code></pre> where the target is a IPv4/IPv6 prefix or IPv4/IPv6 address. The prococol can be <code>icmp</code>, <code>icmp6</code> or <code>udp</code>. The file name must end with <code>.csv</code>.</p> <p>For example: <pre><code>0.0.0.0/0,udp,2,32,1\n8.8.8.0/24,icmp,2,32,6\n2001:4860:4860::8888,icmp6,2,32,6\n</code></pre> If the prefix length is ignored, /24 or /128 is assumed.</p> <p>Some tools offer the <code>prefix_len_v4</code> and <code>prefix_len_v6</code> parameters which allows to split the specified networks and keep the target list short. For instance, if <code>prefix_len_v4=24</code>, then <code>0.0.0.0/0</code> will be split into the 16 millions networks <code>0.0.0.0/24,...,255.255.255.0/24</code>.</p>"},{"location":"concepts/#tool","title":"Tool","text":"<p>A tool defines which probes should be sent based on a target list and the results of a previous measurement round. Examples of such tools are Diamond-Miner, Yarrp or ping.</p> <p>A better name would probably have been an algorithm, to avoid confusion with the actual probing tool that is used, caracal.</p>"},{"location":"concepts/#worker","title":"Worker","text":"<p>A worker coordinates measurement agents. It runs the tool to get the list of probes to send, it sends this list to the agent, and it waits for the results. It is implemented as Dramatiq actors and uses Redis and S3 to exchange data with the agents.</p> <p>The resources required to run a worker depends on the tool and on the number of concurrent measurement agents. To run Diamond-Miner on <code>0.0.0.0/0</code> with a single agent, we recommend at-least 32 GB of memory and 8 CPUs.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>You can set up a production-ready system to orchestrate multiple vantage points from a dedicated API.</p> <p>We provide a <code>docker-compose.yml</code> file to set up Iris locally. Feel free to adapt it with your own configurations. Don't forget to change the default passwords before pushing it to production!</p> <p>First, add the following entry to <code>/etc/hosts</code>: <pre><code>127.0.0.1 api.docker.localhost\n# The lines below are optional:\n127.0.0.1 clickhouse.docker.localhost\n127.0.0.1 minio.docker.localhost\n127.0.0.1 minio-console.docker.localhost\n127.0.0.1 postgres.docker.localhost\n127.0.0.1 redis.docker.localhost\n127.0.0.1 traefik.docker.localhost\n</code></pre></p> <p>Then run the stack and seed the database: <pre><code>docker-compose up --build --detach\ndocker-compose exec api .venv/bin/alembic upgrade head\n</code></pre></p> <p>The API documentation will be available on http://api.docker.localhost/docs.</p>"},{"location":"deployment/#users","title":"Users","text":"<p>By default, a single admin user is created with the email <code>admin@example.org</code> and the password <code>admin</code>. To change its email and/or password, run: <pre><code># Login and retrieve the JWT access token\ncurl -X POST -F 'username=admin@example.org' -F 'password=admin' http://api.docker.localhost/auth/jwt/login\nexport TOKEN=\"copy access_token here\"\n# Patch the user\ncurl -X PATCH -H \"Authorization: Bearer $TOKEN\" -H \"Content-Type: application/json\" -d '{\"email\": \"new@example.org\", \"password\": \"newpassword\"}' http://api.docker.localhost/users/me\n</code></pre></p>"},{"location":"deployment/#configuration","title":"Configuration","text":"<p>In this section we will document the different settings to configure Iris. Most of the settings are commons to the API, the worker and the agent components. All of the settings must be declared in the <code>docker-compose.yml</code> file for each component.</p> Component Settings location Commons iris/commons/settings.py API iris/api/settings.py Worker iris/worker/settings.py Agent iris/agent/settings.py"},{"location":"dev/","title":"Development","text":"<p>Here are some guidelines to make your life easier during the development process.</p>"},{"location":"dev/#prerequisites","title":"Prerequisites","text":"<p>To develop on Iris you need a Python 3.10+ interpreter and Docker.</p> <p>Iris services and their dependencies are hosted behind a Traefik reverse-proxy. To be able to access them from your own machine, you need to add the following entries to <code>/etc/hosts</code>: <pre><code>127.0.0.1 api.docker.localhost\n127.0.0.1 clickhouse.docker.localhost\n127.0.0.1 minio.docker.localhost\n127.0.0.1 minio-console.docker.localhost\n127.0.0.1 postgres.docker.localhost\n127.0.0.1 redis.docker.localhost\n127.0.0.1 traefik.docker.localhost\n</code></pre></p> <p>You also need caracal in your $PATH if you intend to run Iris locally: <pre><code># Use caracal-macos-amd64 for macOS\ncurl -L https://github.com/dioptra-io/caracal/releases/download/v0.15.3/caracal-linux-amd64 &gt; /usr/bin/caracal\nchmod +x /usr/bin/caracal\n</code></pre></p>"},{"location":"dev/#running-iris","title":"Running Iris","text":""},{"location":"dev/#locally","title":"Locally","text":"<pre><code># Create the virtual environment (only once)\npoetry install\n# Launch the external services\ndocker compose up --detach traefik clickhouse minio postgres redis\n# Seed the database\npoetry run alembic upgrade head\n# Launch Iris\npoetry run python -m iris.api\npoetry run python -m iris.agent\npoetry run python -m iris.worker\n# Stop the external services\ndocker compose down\n</code></pre> <p>The API documentation will be available on http://127.0.0.1:8000/docs.</p>"},{"location":"dev/#on-docker","title":"On Docker","text":"<pre><code># Launch Iris and the external services\ndocker-compose up --detach --build\n# Seed the database\npoetry run alembic upgrade head\n# Stop Iris and the external services\ndocker-compose down\n</code></pre> <p>The API documentation will be available on http://api.docker.localhost/docs. By default, the admin user is <code>admin@example.org</code> and the password is <code>admin</code>.</p>"},{"location":"dev/#tests","title":"Tests","text":"<pre><code># Excluding privileged tests\npoetry run pytest\n# Including privileged tests (`@superuser` decorator)\npoetry run sudo pytest\n# Do not delete test artifacts (see `conftest.py`)\nexport IRIS_TEST_CLEANUP=0\npoetry run pytest\n# Generate a coverage report\npoetry run pytest --cov=iris --cov-report=html\n</code></pre>"},{"location":"dev/#pre-commit","title":"pre-commit","text":"<p>Please use the pre-commit hooks to format and lint the code before committing it.</p> <pre><code>poetry run pre-commit install\n# On commit\ngit commit\n# Manually\npoetry run pre-commit run --all-files\n</code></pre>"},{"location":"dev/#release","title":"Release","text":"<p>Please use bumpversion to conduct the releases. The version bump will automatically create a new commit associated with a tag.</p>"}]}